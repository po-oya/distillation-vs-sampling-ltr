{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc242e-8f76-49cd-a0e0-8c6068d2f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f2e83-f46e-47b9-9c47-992ee5beb9fc",
   "metadata": {},
   "source": [
    "# Organizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02c058-17c8-41c5-947c-40fbd5fa1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"\"\n",
    "paths_pointwise = [base_path + \"gm_sample_queries/\", base_path + \"gm_sample_docs/\", base_path + \"dm/\"]\n",
    "paths_lambda = [base_path + \"gm_sample_queries_lambda_loss/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dde46-30a6-4a67-acc5-9b3053e64d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(paths):\n",
    "    df_dict = defaultdict(list)\n",
    "    \n",
    "    ds_map = {\n",
    "        \"ISTELLAS\": \"Istella-S\",\n",
    "        \"MSLR30K\": \"MSLR-WEB30k\",\n",
    "        \"YAHOO\": \"Yahoo!Webscope\"\n",
    "    }\n",
    "    \n",
    "    for path_dir in paths:\n",
    "        for dir_adr in os.listdir(path_dir):\n",
    "            dir_adr = os.path.join(path_dir, dir_adr)\n",
    "            with open(os.path.join(dir_adr, \"config.json\")) as config_file:\n",
    "                config = json.load(config_file)\n",
    "                if \"summary.csv\" in os.listdir(dir_adr):\n",
    "                    df_dict[\"dataset\"].append(ds_map[config[\"Datasets\"][\"Full\"][\"ID\"]])\n",
    "                    if config[\"Experiment\"][\"Name\"] == \"gm_sample_queries\":\n",
    "                        df_dict[\"distillation\"].append(\"Q\")\n",
    "                        df_dict[\"alg\"].append(\"GM\")\n",
    "                        df_dict[\"loss\"].append(\"pointwise\")\n",
    "                    elif config[\"Experiment\"][\"Name\"] == \"gm_sample_docs\":\n",
    "                        df_dict[\"distillation\"].append(\"D\")\n",
    "                        df_dict[\"alg\"].append(\"GM\")\n",
    "                        df_dict[\"loss\"].append(\"pointwise\")\n",
    "                    elif config[\"Experiment\"][\"Name\"] == \"dm\":\n",
    "                        df_dict[\"distillation\"].append(\"L\")\n",
    "                        df_dict[\"alg\"].append(\"DM\")\n",
    "                        df_dict[\"loss\"].append(\"pointwise\")\n",
    "                    elif config[\"Experiment\"][\"Name\"] == \"gm_sample_queries_lambda_loss\":\n",
    "                        df_dict[\"distillation\"].append(\"Q\")\n",
    "                        df_dict[\"alg\"].append(\"GM\")\n",
    "                        df_dict[\"loss\"].append(\"listwise\")\n",
    "                    elif config[\"Experiment\"][\"Name\"] == \"gm_sample_docs_lambda_loss\":\n",
    "                        df_dict[\"distillation\"].append(\"D\")\n",
    "                        df_dict[\"alg\"].append(\"GM\")\n",
    "                        df_dict[\"loss\"].append(\"listwise\")\n",
    "                    else:\n",
    "                        raise NotImplementedError(\"Invalid exp_name {}\".format(config[\"Experiment\"][\"Name\"]))\n",
    "                    df_dict[\"z_rate\"].append(config[\"Datasets\"][\"Distilled\"][\"CompressionRatio\"])\n",
    "                    df_dict[\"rand_init\"].append(config[\"Datasets\"][\"Distilled\"][\"RandInit\"])\n",
    "                    df_dict[\"batch_size\"].append(config[\"Trainer\"][\"BatchSize\"])\n",
    "                    df_dict[\"seed\"].append(config[\"General\"][\"Seed\"])\n",
    "                    smr_df = pd.read_csv(os.path.join(dir_adr, \"summary.csv\"))\n",
    "                    df_dict[\"ndcg_final\"].append(smr_df[\"NDCG@10-FinalEval-DistillInfoTest-Mean\"].item())\n",
    "                    df_dict[\"ndcg_init\"].append(smr_df[\"NDCG@10-InitEval-DistillInfoTest-Mean\"].item())\n",
    "                    df_dict[\"arp_final\"].append(smr_df[\"ARP-FinalEval-DistillInfoTest-Mean\"].item())\n",
    "                    df_dict[\"arp_init\"].append(smr_df[\"ARP-InitEval-DistillInfoTest-Mean\"].item())\n",
    "                    df_dict[\"ndcg_full\"].append(smr_df[\"NDCG@10-InitEval-FullInfoTest\"].item())\n",
    "                    df_dict[\"arp_full\"].append(smr_df[\"ARP-InitEval-FullInfoTest\"].item())\n",
    "                    df_dict[\"r_rate\"].append(smr_df[\"total_qd_vecs_ds\"].item()/smr_df[\"total_qd_vecs_full\"].item())\n",
    "                    df_dict[\"best_step\"].append(smr_df[\"best_step\"].item())\n",
    "                    df_dict[\"dist_valid_ndcg\"].append(smr_df[\"best_valid_ndcg10\"].item())\n",
    "                    df_dict[\"init_valid_ndcg\"].append(smr_df[\"NDCG@10-InitEval-DistilledInfoValidationBest\"].item())\n",
    "                    df_dict[\"exp_path\"].append(dir_adr)\n",
    "                    \n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "    df = df.sort_values(by=[\"distillation\", \"dataset\", \"rand_init\", \"z_rate\"])\n",
    "    df = df.drop_duplicates([\"distillation\", \"dataset\", \"rand_init\", \"z_rate\", \"alg\", \"seed\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862acbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise = preprocess(paths_pointwise)\n",
    "print(df_pointwise.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda = preprocess(paths_lambda)\n",
    "print(df_lambda.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size())\n",
    "cond1 = (df[\"dataset\"] == \"MSLR-WEB30k\") & (df[\"batch_size\"] == 64)\n",
    "cond2 = (df[\"dataset\"] != \"MSLR-WEB30k\")\n",
    "df = df[cond1 | cond2]\n",
    "df = df[df[\"distillation\"] == \"Q\"]\n",
    "print(df.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size())     \n",
    "df_lambda[df_lambda[\"dataset\"] ==  \"MSLR-WEB30k\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6427c9b-4146-442a-9289-fb15c875e58d",
   "metadata": {},
   "source": [
    "# Convergence Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c5331",
   "metadata": {},
   "source": [
    "### MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4420c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"dataset\", \"rand_init\", \"distillation\",])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c94f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"distillation\", \"rand_init\",])[\"best_step\"].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3277920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"rand_init\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee503385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"distillation\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"dataset\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"dataset\", \"rand_init\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3b123",
   "metadata": {},
   "source": [
    "### LambdaLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad42fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"dataset\", \"rand_init\", \"distillation\",])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"distillation\", \"rand_init\",])[\"best_step\"].describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540adcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"rand_init\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3af91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"distillation\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbd101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"dataset\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1245aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"dataset\", \"rand_init\"])[\"best_step\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3059e-aea9-402e-932d-0357f639252d",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe13e4c-daf0-445e-a15a-9ffc6fd98b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ndcg_arp(df, metric):\n",
    "    alpha = 1.645\n",
    "    df[metric+\"_full_mean\"] = np.mean(df[metric+\"_full\"])\n",
    "    df[metric+\"_full_min\"] =  np.mean(df[metric+\"_full\"]) - alpha * np.std(df[metric+\"_full\"])\n",
    "    df[metric+\"_full_max\"] =  np.mean(df[metric+\"_full\"]) + alpha * np.std(df[metric+\"_full\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d5b57-6536-44fe-89e5-d931cb9546fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_res(df, metric):\n",
    "    alpha = 1.645\n",
    "    df[metric+\"_final_min\"] = np.mean(df[metric+\"_final\"]) - alpha * np.std(df[metric+\"_final\"])\n",
    "    df[metric+\"_final_max\"] = np.mean(df[metric+\"_final\"]) + alpha * np.std(df[metric+\"_final\"])\n",
    "    df[metric+\"_final_mean\"] = np.mean(df[metric+\"_final\"])\n",
    "\n",
    "    df[metric+\"_init_min\"] = np.mean(df[metric+\"_init\"]) - alpha * np.std(df[metric+\"_init\"])\n",
    "    df[metric+\"_init_max\"] = np.mean(df[metric+\"_init\"]) + alpha * np.std(df[metric+\"_init\"])\n",
    "    df[metric+\"_init_mean\"] = np.mean(df[metric+\"_init\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def df_plots(df, metric):\n",
    "    # ax, fig = plt.subplots(1, 1, figsize=(8,6))\n",
    "    # mpl.rcParams['font.weight'] = 'bold'\n",
    "    mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "    mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "    fontsize = 20\n",
    "    ms = 18\n",
    "    lw = 2\n",
    "    alg = df[\"alg\"].head(1).item()\n",
    "    dtype = df[\"distillation\"].head(1).item()\n",
    "    Gold = '#FFD700'\n",
    "    Blue = '#1f77b4'\n",
    "    Maroon = '#800000'\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    df = df.groupby([\"z_rate\", \"rand_init\"]).apply(max_min_res, metric)\n",
    "    df = df.drop_duplicates([\"dataset\", \"distillation\", \"z_rate\", \"rand_init\"])\n",
    "    df = df.sort_values([\"dataset\", \"distillation\", \"rand_init\", \"z_rate\"])\n",
    "\n",
    "    df_temp = df[df[\"rand_init\"] == True]\n",
    "    \n",
    "    did = df_temp[\"dataset\"].head(1).item()\n",
    "    distillation_type = df_temp[\"distillation\"].head(1).item()\n",
    "    loss = df_temp[\"loss\"].head(1).item()\n",
    "\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    \n",
    "    ax.plot(x_values, df_temp[metric+\"_final_mean\"], '*--', label=\"{}-{}-R\".format(alg, dtype), markersize=ms, linewidth=lw, color=Gold)\n",
    "    ax.plot(x_values, df_temp[metric+\"_init_mean\"], 'p--', label=\"RV\", markersize=ms, linewidth=lw, color=Maroon)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_final_min\"], df_temp[metric+\"_final_max\"], color=Gold, alpha=0.2)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_init_min\"], df_temp[metric+\"_init_max\"], color=Maroon, alpha=0.2)\n",
    "\n",
    "\n",
    "    df_temp = df[df[\"rand_init\"] == False]\n",
    "\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    \n",
    "    ax.plot(x_values, df_temp[metric+\"_final_mean\"], 'o--', label=\"{}-{}-NR\".format(alg, dtype), markersize=ms, linewidth=lw, color=Blue)\n",
    "    ax.plot(x_values, df_temp[metric+\"_init_mean\"], 'g^--', label=\"{}-S\".format(dtype), markersize=ms, linewidth=lw)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_init_min\"], df_temp[metric+\"_init_max\"], color='g', alpha=0.2)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_final_min\"], df_temp[metric+\"_final_max\"], color=Blue, alpha=0.2)\n",
    "    # ax.errorbar(df_temp[\"z_rate\"], df_temp[metric+\"_final_mean\"], yerr=2*df[metric+\"_final_std\"].head(1))\n",
    "\n",
    "    ax.plot(x_values, df_temp[metric+\"_full_mean\"], '--', label=\"Full\", linewidth=lw*2, color='Purple')\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_full_min\"], df_temp[metric+\"_full_max\"], color='Purple', alpha=0.2)\n",
    "\n",
    "    # ax.legend(loc=\"lower right\")\n",
    "    plt.title(did, fontsize=fontsize)\n",
    "    plt.xlabel(\"Relative dataset size to the full dataset\", fontsize=fontsize)\n",
    "    if metric == \"ndcg\":\n",
    "        y_l = \"NDCG@10\"\n",
    "    elif metric == \"arp\":\n",
    "        y_l = \"ARP\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    plt.ylabel(\"Average {}\".format(y_l), fontsize=fontsize)\n",
    "    x_ticks = x_values\n",
    "    custom_x_ticks = x_ticks*100\n",
    "    custom_x_ticks = custom_x_ticks.round(2).apply(lambda x: str(x)+'%')\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(custom_x_ticks, rotation=22.5)\n",
    "    if metric == \"ndcg\":\n",
    "        y_ticks = np.arange(0, 0.85, 0.1)\n",
    "    elif metric == \"arp\":\n",
    "        y_ticks = np.arange(0, 80, 10)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    plt.legend(fontsize=17, loc='lower left')\n",
    "    \n",
    "\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.savefig(\"./wandb/distillation_figs/{}-{}-{}-{}-{}.pdf\".format(metric, did,alg,distillation_type, loss), transparent=True)\n",
    "    # ax.plot()\n",
    "    plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b848a",
   "metadata": {},
   "source": [
    "### MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise = df_pointwise.groupby([\"dataset\"]).apply(full_ndcg_arp, \"ndcg\")\n",
    "df_pointwise = df_pointwise.groupby([\"dataset\"]).apply(full_ndcg_arp, \"arp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.groupby([\"distillation\", \"dataset\"]).apply(df_plots, \"ndcg\")\n",
    "df_pointwise.groupby([\"distillation\", \"dataset\"]).apply(df_plots, \"arp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8abadc",
   "metadata": {},
   "source": [
    "### LambdaLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47906297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda = df_lambda.groupby([\"dataset\"]).apply(full_ndcg_arp, \"ndcg\")\n",
    "df_lambda = df_lambda.groupby([\"dataset\"]).apply(full_ndcg_arp, \"arp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c37dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda.groupby([\"distillation\", \"dataset\"]).apply(df_plots, \"ndcg\")\n",
    "df_lambda.groupby([\"distillation\", \"dataset\"]).apply(df_plots, \"arp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d464b1",
   "metadata": {},
   "source": [
    "### MSE and LambdaLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de827146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_pl_plots(df, metric):\n",
    "    # ax, fig = plt.subplots(1, 1, figsize=(8,6))\n",
    "    # mpl.rcParams['font.weight'] = 'bold'\n",
    "    mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "    mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "    fontsize = 20\n",
    "    ms = 18\n",
    "    lw = 2\n",
    "    alg = df[\"alg\"].head(1).item()\n",
    "    dtype = df[\"distillation\"].head(1).item()\n",
    "    Gold = '#FFD700'\n",
    "    Blue = '#1f77b4'\n",
    "    Maroon = '#800000'\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    df = df.groupby([\"z_rate\", \"rand_init\", \"loss\"]).apply(max_min_res, metric)\n",
    "    df = df.drop_duplicates([\"dataset\", \"distillation\", \"z_rate\", \"rand_init\", \"loss\"])\n",
    "    df = df.sort_values([\"dataset\", \"distillation\", \"rand_init\", \"z_rate\"])\n",
    "\n",
    "    # print(df.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size())\n",
    "    df_temp = df[df[\"rand_init\"] == True]\n",
    "    did = df_temp[\"dataset\"].head(1).item()\n",
    "    distillation_type = df_temp[\"distillation\"].head(1).item()\n",
    "    \n",
    "\n",
    "    df_temp = df_temp[df_temp[\"loss\"] == \"pointwise\"]\n",
    "    loss = df_temp[\"loss\"].head(1).item()\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    ax.plot(x_values, df_temp[metric+\"_final_mean\"], '*--', label=\"{}-{}-R-P\".format(alg, dtype), markersize=ms, linewidth=lw, color=Gold)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_final_min\"], df_temp[metric+\"_final_max\"], color=Gold, alpha=0.2)\n",
    "\n",
    "    df_temp = df[df[\"rand_init\"] == True]\n",
    "    df_temp = df_temp[df_temp[\"loss\"] == \"listwise\"]\n",
    "    loss = df_temp[\"loss\"].head(1).item()\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    ax.plot(x_values, df_temp[metric+\"_final_mean\"], 'p--', label=\"{}-{}-R-L\".format(alg, dtype), markersize=ms, linewidth=lw, color='#004488')\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_final_min\"], df_temp[metric+\"_final_max\"], color='#004488', alpha=0.2) # Blue\n",
    "\n",
    "\n",
    "    df_temp = df[df[\"rand_init\"] == False]\n",
    "    df_temp = df_temp[df_temp[\"loss\"] == \"pointwise\"]\n",
    "    loss = df_temp[\"loss\"].head(1).item()\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    ax.plot(x_values, df_temp[metric+\"_init_mean\"], 'g^--', label=\"{}-S-P\".format(dtype), markersize=ms, linewidth=lw)\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_init_min\"], df_temp[metric+\"_init_max\"], color='g', alpha=0.2)\n",
    "\n",
    "    ax.plot(x_values, df_temp[metric+\"_full_mean\"], '--', label=\"Full-P\", linewidth=lw*2, color='Purple')\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_full_min\"], df_temp[metric+\"_full_max\"], color='Purple', alpha=0.2)\n",
    "\n",
    "    df_temp = df[df[\"rand_init\"] == False]\n",
    "    df_temp = df_temp[df_temp[\"loss\"] == \"listwise\"]\n",
    "    loss = df_temp[\"loss\"].head(1).item()\n",
    "    x_values = df_temp[\"r_rate\"]\n",
    "    ax.plot(x_values, df_temp[metric+\"_init_mean\"], 'o--', label=\"{}-S-L\".format(dtype), markersize=ms, linewidth=lw, color='#999933') #olive\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_init_min\"], df_temp[metric+\"_init_max\"], color='#999933', alpha=0.2)\n",
    "\n",
    "    ax.plot(x_values, df_temp[metric+\"_full_mean\"], '--', label=\"Full-L\", linewidth=lw*2, color='#663333') # dark red\n",
    "    ax.fill_between(x_values, df_temp[metric+\"_full_min\"], df_temp[metric+\"_full_max\"], color='#663333', alpha=0.2)\n",
    "    \n",
    "\n",
    "\n",
    "    # # ax.legend(loc=\"lower right\")\n",
    "    plt.title(did, fontsize=fontsize)\n",
    "    plt.xlabel(\"Relative dataset size to the full dataset\", fontsize=fontsize)\n",
    "    if metric == \"ndcg\":\n",
    "        y_l = \"NDCG@10\"\n",
    "    elif metric == \"arp\":\n",
    "        y_l = \"ARP\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    plt.ylabel(\"Average {}\".format(y_l), fontsize=fontsize)\n",
    "    x_ticks = x_values\n",
    "    custom_x_ticks = x_ticks*100\n",
    "    custom_x_ticks = custom_x_ticks.round(2).apply(lambda x: str(x)+'%')\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(custom_x_ticks, rotation=22.5)\n",
    "    if metric == \"ndcg\":\n",
    "        y_ticks = np.arange(0, 0.85, 0.1)\n",
    "    elif metric == \"arp\":\n",
    "        y_ticks = np.arange(0, 80, 10)\n",
    "    ax.set_yticks(y_ticks)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    \n",
    "    plt.legend(fontsize=17, loc='lower left')\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.savefig(\"./wandb/distillation_figs/{}-{}-{}-{}-both-loss.pdf\".format(metric, did,alg,distillation_type), transparent=True)\n",
    "    # ax.plot()\n",
    "    plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0da1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl = pd.concat([df_pointwise, df_lambda])\n",
    "df_pl = df_pl[df_pl[\"distillation\"] == \"Q\"]\n",
    "df_pl.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size()\n",
    "\n",
    "df_pl.groupby([\"distillation\", \"dataset\"]).apply(df_pl_plots, \"ndcg\")\n",
    "df_pl.groupby([\"distillation\", \"dataset\"]).apply(df_pl_plots, \"arp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a7607-a4d9-4ce6-8763-dabdaf669704",
   "metadata": {},
   "source": [
    "# Overall Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22883295-9546-4e2a-bf06-71035cf0d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pointwise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069161e-daf4-4da4-b8f6-461890a8665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pointwise.groupby([\"distillation\", \"dataset\", \"rand_init\"]).size())\n",
    "dfo = df_pointwise.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f826eb3-d2f3-432d-addf-becaeb173a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = df_pointwise.copy()\n",
    "# change the valid ndcg into the test performance\n",
    "\n",
    "def aggregate(dfo):\n",
    "    selected_rows = dfo.query(\"rand_init == True\")\n",
    "    row_id = selected_rows[\"dist_valid_ndcg\"].idxmax()    \n",
    "    dfo[\"dp\"] = dfo.loc[row_id][\"ndcg_final\"]\n",
    "    dfo[\"path_distill\"] = dfo.loc[row_id][\"exp_path\"]\n",
    "\n",
    "    selected_rows = dfo.query(\"rand_init == False\")\n",
    "    row_id = selected_rows[\"init_valid_ndcg\"].idxmax()\n",
    "    dfo[\"sp\"] = dfo.loc[row_id][\"ndcg_init\"]\n",
    "    dfo[\"path_sample\"] = dfo.loc[row_id][\"exp_path\"]\n",
    "\n",
    "    return dfo\n",
    "\n",
    "\n",
    "def full_max_agg(dfo):\n",
    "    row_id = dfo[\"ndcg_full\"].idxmax()\n",
    "    dfo[\"full\"] = dfo.loc[row_id][\"ndcg_full\"]\n",
    "    dfo[\"path_full\"] = dfo.loc[row_id][\"exp_path\"]\n",
    "    return dfo\n",
    "\n",
    "\n",
    "dfo = dfo.groupby(by=[\"dataset\"]).apply(full_max_agg)\n",
    "dfo = dfo.groupby(by=[\"distillation\", \"dataset\"]).apply(aggregate)\n",
    "dfo = dfo.drop_duplicates([\"distillation\", \"dataset\", \"alg\"])\n",
    "dfo = dfo.sort_values(by=[\"dataset\", \"rand_init\", \"distillation\", \"alg\"])\n",
    "dfo = dfo[[\"distillation\", \"dataset\", \"alg\", \"dp\", \"sp\", \"full\", \"ndcg_full_mean\", \"path_distill\", \"path_sample\", \"path_full\"]].round(3)\n",
    "print(dfo.groupby([\"distillation\", \"dataset\"]).size())\n",
    "dfo     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ba00b-495e-42c8-8204-3ac02a0a8916",
   "metadata": {},
   "source": [
    "# Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7a393-c2f1-4a6a-aa43-82a312aef707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.stats.multicomp as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e7af1-776e-4a8d-80d5-5f95dc119534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_test(df):\n",
    "    sig_df = defaultdict()\n",
    "    did = df[\"dataset\"].head(1).item()\n",
    "    for idx, row in df.iterrows():\n",
    "    \n",
    "        # distillation ndcgs\n",
    "        mdf = pd.read_csv(os.path.join(row[\"path_distill\"], \"metrics.csv\"))\n",
    "        sig_df[\"dist_\"+row[\"distillation\"]] = mdf[\"NDCG@10-FinalEval-DistillInfoTest\"]\n",
    "        #sampling ndcgs\n",
    "        mdf = pd.read_csv(os.path.join(row[\"path_sample\"], \"metrics.csv\"))\n",
    "        sig_df[\"samp_\"+row[\"distillation\"]] = mdf[\"NDCG@10-InitEval-DistillInfoTest\"]\n",
    "\n",
    "        mdf = pd.read_csv(os.path.join(row[\"path_full\"], \"metrics.csv\"))\n",
    "        sig_df[\"full\"] = mdf[\"NDCG@10-InitEval-FullInfo-Test\"]\n",
    "\n",
    "    sig_df = pd.DataFrame.from_dict(sig_df)\n",
    "\n",
    "    sig_df = sig_df.melt(value_vars=sig_df.columns, var_name=\"model\", value_name=\"metric\")\n",
    "    comparison = mc.MultiComparison(sig_df[\"metric\"], sig_df[\"model\"])\n",
    "    tbl, a1, a2 = comparison.allpairtest(stats.ttest_ind, method= \"bonf\", alpha=0.0001)\n",
    "    # tab_df_list.append(pd.DataFrame(tbl))\n",
    "    print(did, \"\\n\", tbl, \"\\n---------------------------------------\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "dfo.groupby(by=[\"dataset\"]).apply(sig_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c018975-7ef6-47b3-986e-4768b8fed89b",
   "metadata": {},
   "source": [
    "# Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9532b88-ea2f-4ac1-b676-0633f00e569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchltr.datasets import MSLR30K, IstellaS\n",
    "from datasets.yahoo import Yahoo\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29eb070-fb11-41ee-9d45-6765632af45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "location = \"\"\n",
    "\n",
    "mslr = {\n",
    "    \"train\": MSLR30K(location=location+\"MSLR30K/\", split=\"train\", fold=1, normalize=True, filter_queries=True, download=False, validate_checksums=False),\n",
    "    \"valid\": MSLR30K(location=location+\"MSLR30K/\", split=\"vali\", fold=1, normalize=True, filter_queries=True, download=False, validate_checksums=False),\n",
    "    \"test\": MSLR30K(location=location+\"MSLR30K/\", split=\"test\", fold=1, normalize=True, filter_queries=True, download=False, validate_checksums=False)\n",
    "}\n",
    "\n",
    "\n",
    "istella = {\n",
    "    \"train\": IstellaS(location=location+\"ISTELLAS/\", split=\"train\", normalize=True, filter_queries=True, download=False, validate_checksums=False),\n",
    "    \"valid\": IstellaS(location=location+\"ISTELLAS/\", split=\"vali\", normalize=True, filter_queries=True, download=False, validate_checksums=False),\n",
    "    \"test\": IstellaS(location=location+\"ISTELLAS/\", split=\"test\", normalize=True, filter_queries=True, download=False, validate_checksums=False)\n",
    "}\n",
    "\n",
    "yahoo = {\n",
    "    \"train\": Yahoo(location=location+\"YAHOO/\", split=\"train\", normalize=False, filter_queries=True),\n",
    "    \"valid\": Yahoo(location=location+\"YAHOO/\", split=\"vali\", normalize=False, filter_queries=True),\n",
    "    \"test\": Yahoo(location=location+\"YAHOO/\", split=\"test\", normalize=False, filter_queries=True)\n",
    "}\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"MSLR30K\": mslr,\n",
    "    \"IstellaS\": istella,\n",
    "    \"Yahoo\": yahoo\n",
    "}\n",
    "\n",
    "splits = [\"train\", \"valid\", \"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510caa1-7095-49e3-8122-0cc72b546d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "for id in datasets.keys():\n",
    "    split_stats = defaultdict(list)\n",
    "    for split in splits:\n",
    "        n_docs = []\n",
    "        n_non_zero_docs = []\n",
    "        for item in datasets[id][split]:\n",
    "            n_docs.append(item.n.item())\n",
    "            n_non_zero.append(torch.count_nonzero(item.relevance).item())\n",
    "        split_stats[split] = np.sum(n_docs)\n",
    "        if split == \"train\":\n",
    "            split_stats[\"avg_docs\"] = np.mean(n_docs)\n",
    "            split_stats[\"avg_docs_non_zero\"] = np.mean(n_non_zero)\n",
    "    did_dict[\"dataset\"].append(id)\n",
    "    did_dict[\"train\"].append(split_stats[\"train\"])\n",
    "    did_dict[\"valid\"].append(split_stats[\"valid\"])\n",
    "    did_dict[\"test\"].append(split_stats[\"test\"])\n",
    "    did_dict[\"avg_docs\"].append(split_stats[\"avg_docs\"])\n",
    "    did_dict[\"avg_non_zero\"].append(split_stats[\"avg_docs_non_zero\"])\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(did_dict)\n",
    "df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8baa11e-ba1b-4ace-b606-e036177aa008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
